{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ooYhCDnrh_VM",
    "outputId": "c2d2f977-dd3c-4f38-8dd5-20720d12208d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense, Bidirectional\n",
    "from keras.layers import Activation, dot, concatenate\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm_notebook\n",
    "import nltk\n",
    "%matplotlib inline  \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "seaborn.set(font=['AppleMyungjo'], font_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1ubosKwbh_VU",
    "outputId": "4dd0adf9-1e21-4d94-ec70-d3f124e0df54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154304, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = pd.read_csv('dataset/english-german-train.csv')\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3fvVqP7h_Vf"
   },
   "outputs": [],
   "source": [
    "lines.english = lines.english.apply(lambda x: x.lower())\n",
    "lines.german = lines.german.apply(lambda x: str(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJadKeZ6h_Vl"
   },
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation)\n",
    "lines.english = lines.english.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.german = lines.german.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PBItgtI6h_Vr"
   },
   "outputs": [],
   "source": [
    "lines.english = lines.english.apply(lambda x: x.strip())\n",
    "lines.german = lines.german.apply(lambda x: x.strip())\n",
    "\n",
    "lines.english = lines.english.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.german = lines.german.apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFJ24qRGh_Vx"
   },
   "outputs": [],
   "source": [
    "lines.english = lines.english.apply(lambda x: re.sub(\"\\?\\?\", '', x))\n",
    "lines.german = lines.german.apply(lambda x: re.sub(\"\\?\\?\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_hrAZp6h_V3"
   },
   "outputs": [],
   "source": [
    "lines.german = lines.german.apply(lambda x : 'START_ '+ x + '_END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P86TGJpLh_V8",
    "outputId": "b2500e07-3454-401e-b5bf-5110eb1280a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'english', 'german'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDoAUY1nh_WF"
   },
   "outputs": [],
   "source": [
    "del lines['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "MCcLQcnAh_WK",
    "outputId": "9a59f838-c336-4044-e815-c71a522eea30"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>german</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137326</th>\n",
       "      <td>what does tom consider to be the most importan...</td>\n",
       "      <td>START_ was halt tom fur den wichtigsten punkt_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111979</th>\n",
       "      <td>i think im going to faint</td>\n",
       "      <td>START_ ich glaube ich werde ohnmachtig_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21705</th>\n",
       "      <td>tom didnt even know where he was</td>\n",
       "      <td>START_ tom wusste noch nicht einmal wo er war_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129213</th>\n",
       "      <td>thats my affair</td>\n",
       "      <td>START_ das ist meine angelegenheit_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70052</th>\n",
       "      <td>he sounds disappointed</td>\n",
       "      <td>START_ er klingt enttauscht_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83999</th>\n",
       "      <td>you broke your promise</td>\n",
       "      <td>START_ du hast dein versprechen gebrochen_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>he held his breath</td>\n",
       "      <td>START_ er hielt seinen atem an_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127953</th>\n",
       "      <td>tom is changing his clothes</td>\n",
       "      <td>START_ tom kleidet sich um_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112314</th>\n",
       "      <td>tom and mary took the train together</td>\n",
       "      <td>START_ tom und maria fuhren zusammen mit dem z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146241</th>\n",
       "      <td>tom isnt drinking</td>\n",
       "      <td>START_ tom trinkt nicht_END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  english  \\\n",
       "137326  what does tom consider to be the most importan...   \n",
       "111979                          i think im going to faint   \n",
       "21705                    tom didnt even know where he was   \n",
       "129213                                    thats my affair   \n",
       "70052                              he sounds disappointed   \n",
       "83999                              you broke your promise   \n",
       "2326                                   he held his breath   \n",
       "127953                        tom is changing his clothes   \n",
       "112314               tom and mary took the train together   \n",
       "146241                                  tom isnt drinking   \n",
       "\n",
       "                                                   german  \n",
       "137326  START_ was halt tom fur den wichtigsten punkt_END  \n",
       "111979         START_ ich glaube ich werde ohnmachtig_END  \n",
       "21705   START_ tom wusste noch nicht einmal wo er war_END  \n",
       "129213             START_ das ist meine angelegenheit_END  \n",
       "70052                     START_ er klingt enttauscht_END  \n",
       "83999       START_ du hast dein versprechen gebrochen_END  \n",
       "2326                   START_ er hielt seinen atem an_END  \n",
       "127953                     START_ tom kleidet sich um_END  \n",
       "112314  START_ tom und maria fuhren zusammen mit dem z...  \n",
       "146241                        START_ tom trinkt nicht_END  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEUl2TLfh_WS"
   },
   "outputs": [],
   "source": [
    "vocab_english = set()\n",
    "for sent in lines.english:\n",
    "    for word in sent.split():\n",
    "        if word not in vocab_english:\n",
    "            vocab_english.add(word)\n",
    "\n",
    "vocab_german = set()\n",
    "for sent in lines.german:\n",
    "    for word in sent.split():\n",
    "        if word not in vocab_german:\n",
    "            vocab_german.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m4ibOZgph_WY",
    "outputId": "ad2fa9bc-1641-485e-9957-33d277171a71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 7.4321534114475325)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_list=[]\n",
    "for l in lines.german:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "max_length_german = np.max(length_list)\n",
    "max_length_german, np.average(length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dtl0RH2Kh_Wg",
    "outputId": "bbb17929-1ba8-4ef6-d836-6dcecf7bb33f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 6.399587826627955)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_list=[]\n",
    "for l in lines.english:\n",
    "    length_list.append(len(l.split(' ')))\n",
    "max_length_english = np.max(length_list)\n",
    "max_length_english, np.average(length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fEF8_5dHh_Wo",
    "outputId": "5849ace5-cd3b-4c70-f5c6-7a5a87bc236f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14693, 39096)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(vocab_english))\n",
    "target_words = sorted(list(vocab_german))\n",
    "num_encoder_tokens = len(vocab_english)\n",
    "num_decoder_tokens = len(vocab_german)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bhIsJrjgh_Ww",
    "outputId": "029f15a4-b835-4cfd-d4de-08a31ad75f3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39097"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_decoder_tokens += 1 # For zero padding\n",
    "num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bfmJHHBDh_W5"
   },
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jhvt2o1lh_XB"
   },
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "xI7Sqv5wh_XI",
    "outputId": "300e0087-a875-48ad-d740-c91fcaf37355"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>german</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3353</th>\n",
       "      <td>tom says he has actually seen a ghost</td>\n",
       "      <td>START_ tom sagt dass er wirklich einen geist g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17237</th>\n",
       "      <td>dont shout like that i can hear you perfectly</td>\n",
       "      <td>START_ schrei nicht so laut ich kann dich ausg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10670</th>\n",
       "      <td>tom talked with his friends yesterday</td>\n",
       "      <td>START_ tom hat gestern mit seinen freunden ger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57428</th>\n",
       "      <td>she couldnt convince him to buy her a new car</td>\n",
       "      <td>START_ sie konnte ihn nicht uberzeugen ihr ein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140183</th>\n",
       "      <td>tell us about your family</td>\n",
       "      <td>START_ erzahl uns von deiner familie_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54037</th>\n",
       "      <td>smallpox was unknown to native americans</td>\n",
       "      <td>START_ die pocken waren den amerikanischen ure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64140</th>\n",
       "      <td>tom is here to see you</td>\n",
       "      <td>START_ tom ist hier um dich zu sehen_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138641</th>\n",
       "      <td>do you do that often</td>\n",
       "      <td>START_ tun sie das oft_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54019</th>\n",
       "      <td>the water was too hot yesterday</td>\n",
       "      <td>START_ das wasser war gestern zu hei_END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45772</th>\n",
       "      <td>i almost laughed out loud</td>\n",
       "      <td>START_ ich hatte fast laut losgelacht_END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              english  \\\n",
       "3353            tom says he has actually seen a ghost   \n",
       "17237   dont shout like that i can hear you perfectly   \n",
       "10670           tom talked with his friends yesterday   \n",
       "57428   she couldnt convince him to buy her a new car   \n",
       "140183                      tell us about your family   \n",
       "54037        smallpox was unknown to native americans   \n",
       "64140                          tom is here to see you   \n",
       "138641                           do you do that often   \n",
       "54019                 the water was too hot yesterday   \n",
       "45772                       i almost laughed out loud   \n",
       "\n",
       "                                                   german  \n",
       "3353    START_ tom sagt dass er wirklich einen geist g...  \n",
       "17237   START_ schrei nicht so laut ich kann dich ausg...  \n",
       "10670   START_ tom hat gestern mit seinen freunden ger...  \n",
       "57428   START_ sie konnte ihn nicht uberzeugen ihr ein...  \n",
       "140183           START_ erzahl uns von deiner familie_END  \n",
       "54037   START_ die pocken waren den amerikanischen ure...  \n",
       "64140            START_ tom ist hier um dich zu sehen_END  \n",
       "138641                         START_ tun sie das oft_END  \n",
       "54019            START_ das wasser war gestern zu hei_END  \n",
       "45772           START_ ich hatte fast laut losgelacht_END  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6Rz19U5Sh_XS",
    "outputId": "a69943da-1068-4082-9a3e-38246a3c81f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154304, 154304)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english = list(lines.english)\n",
    "german = list(lines.german)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(english)):\n",
    "    x.append(str(english[i]))\n",
    "    y.append(str(german[i]))\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "len(x), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M2UZAHwvh_Xb",
    "outputId": "18df785c-b2c4-4400-d87f-7103940285c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138873,), (15431,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R95xvwgrh_Xi"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_english),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_german),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_german, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xp4Eij4bh_Xn"
   },
   "outputs": [],
   "source": [
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "ALRrtQiNh_Xs",
    "outputId": "542daab3-bee9-46d1-911b-fa1467bf7e9d"
   },
   "outputs": [],
   "source": [
    "english_embedding = Word2Vec.load('embeddings/skipgram-english-256.model')\n",
    "german_embedding = Word2Vec.load('embeddings/skipgram-german-256.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PqMV-gTAh_Xx"
   },
   "outputs": [],
   "source": [
    "eng_tok = Tokenizer()\n",
    "ger_tok = Tokenizer()\n",
    "\n",
    "eng_tok.fit_on_texts(english)\n",
    "ger_tok.fit_on_texts(german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "kqWlbYIfh_X2",
    "outputId": "ca74d738-e57b-47e1-a41a-9cdc923e10f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tmuser/anaconda2/envs/mandav3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "/home/tmuser/anaconda2/envs/mandav3.6/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 14693 is out of bounds for axis 0 with size 14693\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "encoder_embedding_matrix = np.zeros((num_encoder_tokens, latent_dim))\n",
    "for word, i in eng_tok.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = english_embedding[word]\n",
    "        if embedding_vector is not None:\n",
    "            encoder_embedding_matrix[i] = embedding_vector\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "# create a weight matrix for words in training docs\n",
    "decoder_embedding_matrix = np.zeros((num_decoder_tokens, latent_dim))\n",
    "for word, i in ger_tok.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = german_embedding[word]\n",
    "        if embedding_vector is not None:\n",
    "            decoder_embedding_matrix[i] = embedding_vector\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "HPbl3KiNh_X9",
    "outputId": "27d02f1e-17b9-4ac6-81a3-c1ec9a9a2a7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tmuser/anaconda2/envs/mandav3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "encoder_outputs:  Tensor(\"lstm_1/transpose_2:0\", shape=(?, ?, 256), dtype=float32)\n",
      "state_h:  Tensor(\"lstm_1/while/Exit_2:0\", shape=(?, 256), dtype=float32)\n",
      "state_c:  Tensor(\"lstm_1/while/Exit_3:0\", shape=(?, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True, weights=[encoder_embedding_matrix])(encoder_inputs)\n",
    "\n",
    "encoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "print('encoder_outputs: ', encoder_outputs)\n",
    "print('state_h: ', state_h)\n",
    "print('state_c: ', state_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PIprv9q7h_YF"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True, weights=[decoder_embedding_matrix])\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "attention = dot([decoder_outputs, encoder_outputs], axes=[2, 2])\n",
    "\n",
    "attention = Activation('softmax', name='attention')(attention)\n",
    "\n",
    "context = dot([attention, encoder_outputs], axes=[2, 1], name='context')\n",
    "\n",
    "decoder_combined_context = concatenate([context, decoder_outputs], name='decoder_combined_context')\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "4pqXwlJYh_YJ",
    "outputId": "d215d6f7-6920-4a65-fd5c-bc23b6e43e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    3761408     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 256)    10008832    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  525312      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  525312      embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, None, None)   0           lstm_2[0][0]                     \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, None, None)   0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "context (Dot)                   (None, None, 256)    0           attention[0][0]                  \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder_combined_context (Conca (None, None, 512)    0           context[0][0]                    \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 39097)  20056761    decoder_combined_context[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 34,877,625\n",
      "Trainable params: 34,877,625\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPFVHaCgh_YR"
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 16\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYCZj-NGh_YY"
   },
   "outputs": [],
   "source": [
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir='./logs', **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        training_log_dir = os.path.join(log_dir, 'training')\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fit1NC8oh_Yc"
   },
   "outputs": [],
   "source": [
    "log_dir = 'eng_ger_nmt_weights'\n",
    "logging = TrainValTensorBoard(log_dir=log_dir)\n",
    "checkpoint = ModelCheckpoint(os.path.join(log_dir, 'ep{epoch:03d}-val_loss{val_loss:.3f}-val_acc{val_acc:.3f}.h5'),\n",
    "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "_ciTkCudh_Yh",
    "outputId": "2a826d16-5457-4e27-bfec-96e17cd3cf64"
   },
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size,\n",
    "                    callbacks=[logging, checkpoint, reduce_lr, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zL6WiD2kh_Yl"
   },
   "outputs": [],
   "source": [
    "model.load_weights('eng_ger_nmt_weights/ep027-val_loss3.508-val_acc0.559.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_q3smpsMh_Yr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention:  Tensor(\"dot_2/MatMul:0\", shape=(?, ?, ?), dtype=float32)\n",
      "Softmax:  Tensor(\"attention_1/truediv:0\", shape=(?, ?, ?), dtype=float32)\n",
      "Context:  Tensor(\"dot_3/MatMul:0\", shape=(?, ?, 256), dtype=float32)\n",
      "Combined Context:  Tensor(\"concatenate_1/concat:0\", shape=(?, ?, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, [encoder_outputs] + encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "\n",
    "encoder_inf_input = Input(shape=(None, latent_dim))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "\n",
    "attention = dot([decoder_outputs2, encoder_inf_input], axes=[2, 2])\n",
    "print('Attention: ', attention)\n",
    "\n",
    "attention = Activation('softmax', name='attention')(attention)\n",
    "print('Softmax: ', attention)\n",
    "\n",
    "context = dot([attention, encoder_inf_input], axes=[2, 1])\n",
    "print('Context: ', context)\n",
    "\n",
    "decoder_combined_context = concatenate([context, decoder_outputs2])\n",
    "print('Combined Context: ', decoder_combined_context)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "decoder_outputs2 = decoder_dense(decoder_combined_context) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs, encoder_inf_input] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b_13MLn0h_Yw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 256)         3761408   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, None, 256), (None 525312    \n",
      "=================================================================\n",
      "Total params: 4,286,720\n",
      "Trainable params: 4,286,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'lstm_1/transpose_2:0' shape=(?, ?, 256) dtype=float32>,\n",
       " <tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>,\n",
       " <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.summary()\n",
    "encoder_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_s9XQdPVh_Y6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 256)    10008832    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  525312      embedding_2[1][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, None, 256)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, None, None)   0           lstm_2[1][0]                     \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, None, None)   0           dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, None, 256)    0           attention[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 512)    0           dot_3[0][0]                      \n",
      "                                                                 lstm_2[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 39097)  20056761    concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 30,590,905\n",
      "Trainable params: 30,590,905\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<tf.Tensor 'input_2:0' shape=(?, ?) dtype=float32>,\n",
       "  <tf.Tensor 'input_5:0' shape=(?, ?, 256) dtype=float32>,\n",
       "  <tf.Tensor 'input_3:0' shape=(?, 256) dtype=float32>,\n",
       "  <tf.Tensor 'input_4:0' shape=(?, 256) dtype=float32>],\n",
       " [<tf.Tensor 'dense_1_1/truediv:0' shape=(?, ?, 39097) dtype=float32>,\n",
       "  <tf.Tensor 'lstm_2_1/while/Exit_2:0' shape=(?, 256) dtype=float32>,\n",
       "  <tf.Tensor 'lstm_2_1/while/Exit_3:0' shape=(?, 256) dtype=float32>])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_model.summary()\n",
    "decoder_model.input, decoder_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7uY6UdjVh_ZH"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    [encoder_output, h, c] = encoder_model.predict(input_seq)\n",
    "    states_value = [h, c]\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    \n",
    "    #return\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq, encoder_output] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 100):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eIxCqHP_h_ZL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fa8a1758828>\tname:input_2\n",
      "<keras.layers.embeddings.Embedding object at 0x7fa8a17587f0>\tname:embedding_2\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fa6f73c5b00>\tname:input_3\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fa6f73c5668>\tname:input_4\n",
      "<keras.layers.recurrent.LSTM object at 0x7fa8a1758908>\tname:lstm_2\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fa6f73c54e0>\tname:input_5\n",
      "<keras.layers.merge.Dot object at 0x7fa8a1758c18>\tname:dot_2\n",
      "<keras.layers.core.Activation object at 0x7fa6f7343d30>\tname:attention\n",
      "<keras.layers.merge.Dot object at 0x7fa6f74e7198>\tname:dot_3\n",
      "<keras.layers.merge.Concatenate object at 0x7fa6f72aa3c8>\tname:concatenate_1\n",
      "<keras.layers.core.Dense object at 0x7fa8a17032e8>\tname:dense_1\n"
     ]
    }
   ],
   "source": [
    "layers = decoder_model.layers\n",
    "for l in layers:\n",
    "    print('%s\\tname:%s' % (str(l), l.name))\n",
    "    \n",
    "assert(model.layers[7] == model.get_layer('attention'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "il-iybXWh_ZQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.training.Model object at 0x7fa8a42f1710>\n",
      "[(None, None, 39097), (None, 256), (None, 256), (None, None, None)] [(None, None), (None, None, 256), (None, 256), (None, 256)]\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 256)    10008832    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  525312      embedding_2[1][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, None, 256)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, None, None)   0           lstm_2[1][0]                     \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, None, None)   0           dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, None, 256)    0           attention[0][0]                  \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 512)    0           dot_3[0][0]                      \n",
      "                                                                 lstm_2[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 39097)  20056761    concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 30,590,905\n",
      "Trainable params: 30,590,905\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "attention_layer = decoder_model.get_layer('attention') # or model.layers[7]\n",
    "attention_model = Model(inputs=decoder_model.inputs, outputs=decoder_model.outputs + [attention_layer.output])\n",
    "\n",
    "print(attention_model)\n",
    "print(attention_model.output_shape, attention_model.input_shape)\n",
    "attention_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OS4edR9lh_ZV"
   },
   "outputs": [],
   "source": [
    "def attent_and_generate(input_seq):\n",
    "    decoded_sentence = []\n",
    "    \n",
    "    [encoder_output, h, c] = encoder_model.predict(input_seq)\n",
    "    states_value = [h, c]\n",
    "    \n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "    \n",
    "    stop_condition = False\n",
    "    attention_density = []\n",
    "    index = []\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c, attention = attention_model.predict([target_seq, encoder_output] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence.append(sampled_char)\n",
    "    \n",
    "        if ('_END' in sampled_char) or len(decoded_sentence) > 50:\n",
    "            stop_condition = True\n",
    "            \n",
    "        states_value = [h, c]\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        attention_density.append((sampled_char, attention[0][0]))\n",
    "      \n",
    "    return np.array(attention_density), ' '.join(decoded_sentence)\n",
    "\n",
    "\n",
    "def visualize(text, encoder_input):\n",
    "    attention_weights, decoded_sent = attent_and_generate(encoder_input)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    mats = []\n",
    "    dec_inputs = []\n",
    "    for dec_ind, attn in attention_weights:\n",
    "        mats.append(attn[:len(text[0].split(' '))].reshape(-1))\n",
    "        dec_inputs.append(dec_ind)\n",
    "        \n",
    "    attention_mat = np.transpose(np.array(mats))\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(attention_mat)\n",
    "    ax.set_xticks(np.arange(attention_mat.shape[1]))\n",
    "    ax.set_yticks(np.arange(attention_mat.shape[0]))\n",
    "\n",
    "    ax.set_xticklabels([inp for inp in dec_inputs])\n",
    "    ax.set_yticklabels([w for w in str(text[0]).split(' ')])\n",
    "\n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "    plt.show()\n",
    "    return decoded_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "24VRfL3kh_Za"
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zDLEFN9Ah_Zg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tom told mary about his new car']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English Sentence: tom told mary about his new car\n",
      "Actual German:  tom erzahlte maria uber sein neues auto\n",
      "Predicted German: tom sagte maria ihm seine neuen wagen\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(encoder_input, actual_output), _ = next(train_gen)\n",
    "print(X_train[k:k+1])\n",
    "decoded_sent = visualize(X_train[k:k+1], encoder_input)\n",
    "print('Input English Sentence:', X_train[k:k+1][0])\n",
    "print('Actual German:', y_train[k:k+1][0][6:-4])\n",
    "print('Predicted German:', decoded_sent[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zu4-JH90RTm-"
   },
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NMT-Training-Inference.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
